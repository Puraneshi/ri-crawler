{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Recuperação de Informação </h1>\n",
    "<h2> Trabalho 1 - Coletor </h2>\n",
    "<h2>Leonardo Resende </h2>\n",
    "<img style=\"float:left\" src=\"imgs/vamos_coletar.png\"><img style=\"float:left\" src=\"imgs/me.png\" width=255>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Parte 1: A Coleta</h3><br>\n",
    "\n",
    "O coletor é estruturado dentro do conceito teórico estudado em aula:\n",
    "\n",
    "   * Temos uma estrutura que representa os `domínios`, assim como suas restrições de acesso\n",
    "   <br>\n",
    "   * Temos uma estrutura que representa o `escalonador`, organizando as páginas coletadas e repassando as próximas para o `baixador`\n",
    "   <br>\n",
    "   * Temos uma estrutura que representa o `baixador`, visitando as páginas e coletando novas url para coleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler.scheduler import Scheduler\n",
    "from crawler.page_fetcher import PageFetcher\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_agent = 'citycrawler (ricitycrawler.wordpress.com)'\n",
    "page_limit = 1\n",
    "depth_limit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL https://prefeitura.pbh.gov.br inserida!\n"
     ]
    }
   ],
   "source": [
    "obj_url = [urlparse('https://prefeitura.pbh.gov.br')]\n",
    "obj_scheduler = Scheduler(usr_agent, page_limit, depth_limit, obj_url)\n",
    "obj_fetcher = PageFetcher(obj_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fetcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Páginas coletadas\n",
    "obj_scheduler.page_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URLs coletadas\n",
    "len(obj_scheduler.set_discovered_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos acima um exemplo de uma coleta!<br>\n",
    "Transformamos a string em um objeto url, que é convertida para um `domínio` (Domain) dentro do `escalonador` (Scheduler), vemos o mesmo com um user_agent (identificação do coletor), o limite e profundidade da coleta.<br>\n",
    "Por último, vemos que o `baixador` (PageFetcher) recebe o `escalonador` e roda com uma página.<br>\n",
    "\n",
    "<h4>Repare que visitamos UMA página, mas dentro dela coletamos muitas outras urls.<br>\n",
    "Isso é importante para distinguir que coletar uma PÁGINA é diferente de coletar uma URL </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Parte 2: Políticas & Polidez</h3><br>\n",
    "\n",
    "Voltando ao `user_agent` mencionado previamente:\n",
    "\n",
    "   * Páginas web tem, em sua maioria, um arquivo chamado `robots.txt` na raiz do domínio\n",
    "   <br>\n",
    "   * Esse arquivo indica o que a administração do domínio permite ou não deseja que seja coletado\n",
    "   <br>\n",
    "   * É boa prática que coletores se identifiquem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estes pontos são importantes e para isso, usamos um método que baixa e implementa as regras do `robots.txt` de cada domínio que visitamos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler.scheduler import Scheduler\n",
    "from urllib.parse import urlparse\n",
    "from urllib import robotparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_agent = 'citycrawler (ricitycrawler.wordpress.com)'\n",
    "obj_scheduler = Scheduler(usr_agent, 1, 1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Podemos visitar??', True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_url = urlparse('https://prefeitura.pbh.gov.br')\n",
    "'''Podemos visitar??''', obj_scheduler.can_fetch_page(obj_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Podemos visitar??', False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_url = urlparse('https://prefeitura.pbh.gov.br/web.config')\n",
    "'''Podemos visitar??''', obj_scheduler.can_fetch_page(obj_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, foi criado um site no wordpress para que a administração de um site que fique curiosa com os acessos ao domínio possa obter mais informações:\n",
    "<br><br>\n",
    "<a style=\"font-family:Papyrus; font-size:2em;\" href=\"https://ricitycrawler.wordpress.com\" title=\"Crawler HomePage\">RI City Crawler</a>\n",
    "<img style=\"float:center\" src=\"imgs/site.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Parte 3: Mãos na massa</h3><br>\n",
    "\n",
    "Segue a coleta, utilizando várias `threads` que se encontra no arquivo `coleta.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler.scheduler import Scheduler\n",
    "from crawler.page_fetcher import PageFetcher\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_agent = 'citycrawler (ricitycrawler.wordpress.com)'\n",
    "page_limit = 5000\n",
    "depth_limit = 6\n",
    "thread_number = 200\n",
    "url_seeds = ['https://prefeitura.pbh.gov.br',\n",
    "             'https://www.capital.sp.gov.br',\n",
    "             'https://prefeitura.rio',\n",
    "             'https://prefeitura.poa.br',\n",
    "             'https://www.goiania.go.gov.br',\n",
    "             'https://www.fortaleza.ce.gov.br',\n",
    "             'https://www.curitiba.pr.gov.br',\n",
    "             'http://www.belem.pa.gov.br',\n",
    "             'https://www.df.gov.br',\n",
    "             'https://www.saopaulo.sp.leg.br',\n",
    "             'https://www.pmf.sc.gov.br',\n",
    "             'https://www.natal.rn.gov.br',\n",
    "             'https://boavista.rr.gov.br',\n",
    "             'https://macae.rj.gov.br',\n",
    "             'https://www.vitoria.es.gov.br/',\n",
    "             'https://www.ibge.gov.br'\n",
    "            ]\n",
    "arr_url_seeds = []\n",
    "for url in url_seeds:\n",
    "    arr_url_seeds.append(urlparse(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL https://prefeitura.pbh.gov.br inserida!\n",
      "URL https://www.capital.sp.gov.br inserida!\n",
      "URL https://prefeitura.rio inserida!\n",
      "URL https://prefeitura.poa.br inserida!\n",
      "URL https://www.goiania.go.gov.br inserida!\n",
      "URL https://www.fortaleza.ce.gov.br inserida!\n",
      "URL https://www.curitiba.pr.gov.br inserida!\n",
      "URL http://www.belem.pa.gov.br inserida!\n",
      "URL https://www.df.gov.br inserida!\n",
      "URL https://www.saopaulo.sp.leg.br inserida!\n",
      "URL https://www.pmf.sc.gov.br inserida!\n",
      "URL https://www.natal.rn.gov.br inserida!\n",
      "URL https://boavista.rr.gov.br inserida!\n",
      "URL https://macae.rj.gov.br inserida!\n",
      "URL https://www.vitoria.es.gov.br/ inserida!\n",
      "URL https://www.ibge.gov.br inserida!\n",
      "The page count has reached a new milestone: 100\n",
      "The page count has reached a new milestone: 200\n",
      "The page count has reached a new milestone: 300\n",
      "The page count has reached a new milestone: 400\n",
      "The page count has reached a new milestone: 500\n",
      "The page count has reached a new milestone: 600\n",
      "The page count has reached a new milestone: 700\n",
      "The page count has reached a new milestone: 800\n",
      "The page count has reached a new milestone: 900\n",
      "The page count has reached a new milestone: 1000\n",
      "The page count has reached a new milestone: 1100\n",
      "The page count has reached a new milestone: 1200\n",
      "The page count has reached a new milestone: 1300\n",
      "The page count has reached a new milestone: 1400\n",
      "The page count has reached a new milestone: 1500\n",
      "The page count has reached a new milestone: 1600\n",
      "The page count has reached a new milestone: 1700\n",
      "The page count has reached a new milestone: 1800\n",
      "The page count has reached a new milestone: 1900\n",
      "The page count has reached a new milestone: 2000\n"
     ]
    }
   ],
   "source": [
    "obj_scheduler = Scheduler(usr_agent, page_limit, depth_limit, arr_url_seeds)\n",
    "\n",
    "arr_obj_fetcher = []\n",
    "for _ in range(thread_number):\n",
    "    arr_obj_fetcher.append(PageFetcher(obj_scheduler))\n",
    "    arr_obj_fetcher[-1].start()\n",
    "for thread in arr_obj_fetcher:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_scheduler.page_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Parte 4: Mar de Threads</h3><br>\n",
    "\n",
    "Usando uma coleta de 100 páginas, foram obtidos os seguintes dados de threads x tempo levado:\n",
    "\n",
    "   * Os pontos da análise das threads foram: 1, 6, 11, 16, 21, 30, 50, 70, 90, 110, 130, 150<br>\n",
    "   <br>\n",
    "   * O pior resultado foi com uma thread, quase 110 segundos para a coleta<br>\n",
    "   <br>\n",
    "   * O melhor resultado foi com 150 threads com o tempo de 42 segundos (talvez essa seja a pergunta para a resposta??)<br>\n",
    "   <br>\n",
    "   * O interessante é que com 70 threads, tivemos uma performance semelhante, mais testes serão feitos pra além do relatório."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center\" src=\"imgs/myplot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análize foi feita no arquivo \"~/analisis/main.py\" e editada com procreate para visualização personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
